# The Avatarium

**Avatarium** is an open-source AIâ€“VR storytelling platform where digital characters evolve, remember, and respond â€” merging narrative storytelling with embodied interaction.  
Each avatar carries a distinct backstory, memory, and agency, capable of perceiving, remembering, and reacting to the user and the wider fictional world.  

Built as a modular, VR-ready environment, Avatarium integrates large-language models, generative imagery, and long-term character memory systems to create continuous, emotionally rich experiences. Every exchange can subtly reshape a characterâ€™s history â€” and, in turn, the shared world they inhabit.

---
---

## ğŸŒŠ Example Characters

| Portrait | Description |
|----------|-------------|
|  <img src="./assets/sera.png" alt="Sera â€” transhuman sibling adapted for aquatic life" width="100%"/> | Sera. A transhuman woman adapted for oceanic environments â€” calm, perceptive, and spiritually attuned. Sera acts as both guide and mirror, helping users navigate emotional and narrative depths within Avatarium. |
| <img src="./assets/sera4.png" alt="Sera floating a water sphere" width="100%"/> Behaviour |

<p align="center"><em>
Together, Sera and Soren represent the twin currents of Avatarium â€” empathy and inquiry, feeling and thought, always flowing toward new forms of consciousness.
</em></p>

---

## ğŸŒŸ Current Capabilities (2025)

### ğŸ§  Character Memory & Backstory
- YAMLâ€‘based longâ€‘term memory and persona system per character.
- Stores dialogue summaries, emotional tone, and factual events.
- Compresses and sends backstory + chat context to LLM for continuity.
- In development: **Backstory Forge UI** for interactive personality editing.

### ğŸ’¬ Conversational Intelligence
- Inâ€‘character dialogue powered by either:
  - **OpenAI GPTâ€‘4oâ€‘mini** (default), or  
  - **Ollama local models** (e.g. `llama3.1:8b`, `phi3:3.8b`).
- Context-aware responses shaped by memory, emotion, and narrative state.

### ğŸ¨ Visual Generation & Editing
- Dynamic image rendering through **ComfyUI** pipelines.
- Real-time visual updates: pose, expression, camera, and mood  
- Two-way link between dialogue and image states  
- Local file structure supports scene-based rendering and visual history  

### ğŸ§© Architecture Integration
- Unified state object defines `persona`, `memory`, `scene`, and `emotion`.
- Modular backend lets components (LLM, image, memory) sync in real time.
- Supports remote or LANâ€‘based model execution.

---
## ğŸ­ Soren â€” Pose Gallery

<p align="center"><em>
Examples of in-game behavioural changes based on user chat and character backstory.
</em></p>

<table>
  <tr>
    <td align="center" width="50%">
      <img src="./assets/Soren02.png" alt="Soren â€” smiling" width="100%"/><br/>
      <sub>Smiling</sub>
    </td>
    <td align="center" width="50%">
      <img src="./assets/Soren03.png" alt="Soren â€” worried" width="100%"/><br/>
      <sub>Worried</sub>
    </td>
  </tr>
  <tr>
    <td align="center" width="50%">
      <img src="./assets/Soren04.png" alt="Soren â€” standing at the beach" width="100%"/><br/>
      <sub>Standing at the beach</sub>
    </td>
    <td align="center" width="50%">
      <img src="./assets/Soren05.png" alt="Soren â€” at the beach, looking at a holographic display" width="100%"/><br/>
      <sub>Beach + holographic display</sub>
    </td>
  </tr>
</table>

<p align="center"><em>
Soren â€” a transhuman explorer shaped by oceanic evolution.  
His story unfolds through memory, perception, and dialogue.
</em></p>




## ğŸš§ In Development

| Area | Description |
|------|--------------|
| **Backstory Forge** | Web tool for creating and editing character memories, traits, and histories. |
| **Emotion Feedback** | Integrating webcamâ€‘based user emotion detection (ML Kit / MediaPipe). [in progress](https://github.com/shickselate/face-capture) |
| **Avatar Selfâ€‘Perception** | LLMs gain awareness of their own appearance via image captioning (CLIP / BLIP). |
| **Unified Scene Manager** | Links image state, conversation history, and world context. |

---

## ğŸ› ï¸ Dependencies

| Component | Purpose |
|------------|----------|
| **Gradio** | Web UI and reactive state management |
| **Requests** | Communication with LLMs and ComfyUI |
| **PyYAML** | Memory persistence per character |
| **ComfyUI** | Image generation and editing workflows |
| **Ollama (optional)** | Local LLM execution |

Install with:
```bash
pip install gradio requests pyyaml pillow
```

---

## ğŸš€ Usage

1. Launch **ComfyUI** with your `nunchaku_edit.py` workflow.
2. Set your API key (for OpenAI users):
   ```bash
   export OPENAI_API_KEY=sk-...
   ```
3. Start Avatarium:
   ```bash
   python companion_web_v10g.py
   ```
4. Open the app at `http://127.0.0.1:7860` and begin your conversation.
5. Watch the characterâ€™s dialogue, memory, and visuals evolve in real time.

---

## ğŸ§­ Roadmap

| Phase | Focus | Description |
|--------|--------|-------------|
| **1. Consolidation** | Unified architecture | Merge LLM, image, and memory systems under a single state model. |
| **2. Emotion Layer** | User expression integration | Webcam emotion detection â†’ LLM awareness. |
| **3. Selfâ€‘Perception** | Visual feedback to avatars | Let avatars â€œsee themselvesâ€ via image analysis. |
| **4. Tooling & UX** | Creatorâ€‘facing tools | Backstory Forge, Scene Editor, persistent world logs. |

---

## ğŸ—‚ï¸ Repository Layout

```
/companion_web_v10g.py   # Main app: LLM + ComfyUI + Gradio interface
/memory_manager.py       # Persistent perâ€‘character memory
/album_manager.py        # Image gallery and metadata
/memory/                 # Character YAMLs
/assets/                 # Character portraits and scenes
/outputs/                # Rendered images
```

---

## ğŸ’¬ Acknowledgements

Developed by **Stephen Hicks**  with iterative AI collaboration.  
Part of the broader **Fusion Shift / Avatarium** universe â€” exploring intimacy, presence, and the boundaries between AI, art, and storytelling.

---

Â© 2025 Stephen Hicks â€” Released under the **MIT License**.


